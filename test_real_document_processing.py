#!/usr/bin/env python3
"""
    --- AUTO-GENERATED DOCSTRING ---
    Table of content is automatically generated by Agent Docstrings v1.3.5
    
    Classes/Functions:
        - test_real_document_processing() (line 26)
        - main() (line 170)
    --- END AUTO-GENERATED DOCSTRING ---

Test Enhanced SciRAG with real scientific documents from ISRA 2017 dataset.
"""
from scirag.enhanced_processing import (
    MathematicalProcessor, ContentClassifier, EnhancedChunker,
    EnhancedDocumentProcessor, AssetProcessor, GlossaryExtractor,
    EnhancedChunk, ContentType
)
import sys
import os
from pathlib import Path

# Add the parent directory of 'scirag' to the Python path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '.')))


def test_real_document_processing():
    """Test enhanced processing with real scientific document."""
    print("ğŸš€ Testing Enhanced SciRAG with Real Scientific Document")
    print("=" * 60)

    # Read the real document
    doc_path = Path("txt_files/1604.01424v3.txt")
    if not doc_path.exists():
        print(f"âŒ Document not found: {doc_path}")
        return False

    with open(doc_path, 'r', encoding='utf-8') as f:
        document_text = f.read()

    print(f"ğŸ“„ Loaded document: {doc_path}")
    print(f"ğŸ“Š Document length: {len(document_text)} characters")
    print(f"ğŸ“Š Document lines: {len(document_text.splitlines())}")

    # Initialize processors
    print("\nğŸ”§ Initializing Enhanced Processing Components...")
    math_processor = MathematicalProcessor()
    content_classifier = ContentClassifier()
    enhanced_chunker = EnhancedChunker()
    asset_processor = AssetProcessor()
    glossary_extractor = GlossaryExtractor()

    print("âœ… All processors initialized successfully")

    # Test mathematical processing
    print("\nğŸ§® Testing Mathematical Processing...")
    math_equations = [
        "H_0 = 73.24 Â± 1.74 km s^{-1} Mpc^{-1}",
        "E = mc^2",
        "\\frac{d}{dt} = \\frac{\\partial}{\\partial t} + \\vec{v} \\cdot \\nabla",
        "\\Lambda CDM",
        "z \\sim 1000"]

    math_results = []
    for equation in math_equations:
        result = math_processor.process_equation(equation)
        math_results.append(result)
        print(
            f"   âœ… {equation[:30]}... â†’ {result['equation_type']} (complexity: {result['complexity_score']:.2f})")

    # Test content classification
    print("\nğŸ·ï¸  Testing Content Classification...")
    test_texts = [
        "The Hubble constant H_0 = 73.24 Â± 1.74 km s^{-1} Mpc^{-1}",
        "Figure 1: Evolution of error budget in H_0 measurements",
        "Table 2: Cepheid distance measurements",
        "This is regular prose content about cosmology",
        "Definition: The Hubble constant is the rate of expansion of the universe"]

    classification_results = []
    for text in test_texts:
        content_type = content_classifier.classify_content(text, {})
        classification_results.append((text, content_type))
        print(f"   âœ… '{text[:40]}...' â†’ {content_type.value}")

    # Test enhanced chunking
    print("\nğŸ“¦ Testing Enhanced Chunking...")
    chunks = enhanced_chunker.chunk_document(
        document_text, "hubble_constant_paper")
    print(f"   âœ… Generated {len(chunks)} enhanced chunks")

    # Analyze chunk types
    chunk_types = {}
    for chunk in chunks:
        chunk_type = chunk.content_type.value
        chunk_types[chunk_type] = chunk_types.get(chunk_type, 0) + 1

    print("   ğŸ“Š Chunk type distribution:")
    for chunk_type, count in chunk_types.items():
        print(f"      {chunk_type}: {count}")

    # Test asset processing
    print("\nğŸ–¼ï¸  Testing Asset Processing...")
    asset_texts = [
        "Figure 1: Evolution of error budget in H_0 measurements",
        "Table 2: Cepheid distance measurements",
        "Figure 3: Hubble diagram showing magnitude-redshift relation"
    ]

    asset_results = []
    for text in asset_texts:
        result = asset_processor.process_asset(text, "figure")
        if result:
            asset_results.append(result)
            print(
                f"   âœ… {text[:40]}... â†’ {result.asset_type} (confidence: {result.confidence:.2f})")
        else:
            print(f"   âš ï¸  {text[:40]}... â†’ No asset detected")

    # Test glossary extraction
    print("\nğŸ“š Testing Glossary Extraction...")
    glossary_terms = glossary_extractor.extract_glossary_terms(
        document_text, "hubble_constant_paper")
    print(f"   âœ… Extracted {len(glossary_terms)} glossary terms")

    for i, term in enumerate(glossary_terms[:5]):  # Show first 5 terms
        print(f"      {i + 1}. {term.term}: {term.definition[:60]}...")

    # Test integrated processing
    print("\nğŸ”„ Testing Integrated Processing Pipeline...")
    doc_processor = EnhancedDocumentProcessor()

    # Process a sample of the document
    sample_text = document_text[:5000]  # First 5000 characters
    processed_chunks = doc_processor.process_document(
        sample_text, "hubble_sample")

    print(
        f"   âœ… Processed {
            len(processed_chunks)} chunks with integrated pipeline")

    # Analyze processed chunks
    enhanced_features = {
        'mathematical': sum(
            1 for c in processed_chunks if c.mathematical_content), 'assets': sum(
            1 for c in processed_chunks if c.asset_content), 'glossary': sum(
                1 for c in processed_chunks if c.glossary_content)}

    print("   ğŸ“Š Enhanced features found:")
    for feature, count in enhanced_features.items():
        print(f"      {feature}: {count}")

    # Performance summary
    print("\nğŸ“ˆ Performance Summary:")
    print(
        f"   âœ… Mathematical processing: {
            len(math_results)} equations processed")
    print(
        f"   âœ… Content classification: {
            len(classification_results)} texts classified")
    print(f"   âœ… Enhanced chunking: {len(chunks)} chunks generated")
    print(f"   âœ… Asset processing: {len(asset_results)} assets processed")
    print(f"   âœ… Glossary extraction: {len(glossary_terms)} terms extracted")
    print(
        f"   âœ… Integrated processing: {
            len(processed_chunks)} chunks processed")

    return True


def main():
    """Run the real document processing test."""
    try:
        success = test_real_document_processing()
        if success:
            print("\nğŸ‰ Real Document Processing Test PASSED!")
            print("   Enhanced SciRAG successfully processed a real scientific paper")
            print("   with mathematical equations, figures, tables, and definitions.")
        else:
            print("\nâŒ Real Document Processing Test FAILED!")
            return 1
    except Exception as e:
        print(f"\nâŒ Test failed with error: {e}")
        import traceback
        traceback.print_exc()
        return 1

    return 0


if __name__ == "__main__":
    exit(main())