"""
    --- AUTO-GENERATED DOCSTRING ---
    Table of content is automatically generated by Agent Docstrings v1.3.5
    
    Classes/Functions:
        - TestPerformanceBenchmarks (line 45):
            - test_mathematical_processing_performance(mathematical_processor, sample_equations) (line 50)
            - test_content_classification_performance(content_classifier) (line 72)
            - test_enhanced_chunking_performance(enhanced_chunker, sample_text) (line 100)
            - test_memory_usage() (line 122)
            - test_large_document_processing(sample_documents) (line 152)
        - TestScalabilityBenchmarks (line 182):
            - test_concurrent_processing() (line 187)
            - test_batch_processing_performance(enhanced_chunker) (line 245)
        - TestResourceUsageBenchmarks (line 271):
            - test_cpu_usage(mathematical_processor, sample_equations) (line 275)
            - test_memory_leak_detection() (line 295)
            - test_processing_time_consistency(mathematical_processor) (line 324)
        - TestPerformanceThresholds (line 354):
            - test_mathematical_processing_threshold(mathematical_processor) (line 358)
            - test_content_classification_threshold(content_classifier) (line 372)
            - test_chunking_threshold(enhanced_chunker) (line 386)
    --- END AUTO-GENERATED DOCSTRING ---

Performance and Benchmark Tests for Enhanced SciRAG

This module contains performance tests and benchmarks to ensure
the Enhanced SciRAG system meets performance requirements.
"""
import pytest
import time
import psutil
import tempfile
from pathlib import Path
from typing import List, Dict, Any
import statistics

from scirag.enhanced_processing import (
    MathematicalProcessor, ContentClassifier, EnhancedChunker,
    AssetProcessor, GlossaryExtractor, EnhancedDocumentProcessor
)
from scirag import SciRagEnhanced


class TestPerformanceBenchmarks:
    """Performance benchmark tests."""

    @pytest.mark.performance
    @pytest.mark.slow
    def test_mathematical_processing_performance(
            self, mathematical_processor, sample_equations):
        """Test mathematical processing performance."""
        # Process multiple equations and measure time
        start_time = time.time()

        for equation in sample_equations * 10:  # Process 50 equations
            result = mathematical_processor.process_equation(equation)
            assert result is not None

        end_time = time.time()
        processing_time = end_time - start_time

        # Should process 50 equations in reasonable time
        assert processing_time < 10.0, f"Processing 50 equations took {processing_time:.2f}s"

        # Calculate processing rate
        equations_per_second = 50 / processing_time
        print(
            f"Mathematical processing rate: {equations_per_second:.2f} equations/second")

    @pytest.mark.performance
    def test_content_classification_performance(self, content_classifier):
        """Test content classification performance."""
        test_texts = [
            "This is regular prose text.",
            "Figure 1: A diagram showing the process.",
            "Table 2: Experimental results are shown below.",
            "The equation E = mc^2 represents energy equivalence.",
            "This is another piece of prose content."
        ] * 20  # 100 texts

        start_time = time.time()

        for text in test_texts:
            content_type = content_classifier.classify_content(text, {})
            assert content_type is not None

        end_time = time.time()
        processing_time = end_time - start_time

        # Should process 100 texts in reasonable time
        assert processing_time < 5.0, f"Processing 100 texts took {processing_time:.2f}s"

        # Calculate processing rate
        texts_per_second = 100 / processing_time
        print(
            f"Content classification rate: {texts_per_second:.2f} texts/second")

    @pytest.mark.performance
    def test_enhanced_chunking_performance(
            self, enhanced_chunker, sample_text):
        """Test enhanced chunking performance."""
        # Create a larger text by repeating sample text
        large_text = sample_text * 10

        start_time = time.time()

        chunks = enhanced_chunker.chunk_text(large_text, "test_doc")

        end_time = time.time()
        processing_time = end_time - start_time

        # Should process large text in reasonable time
        assert processing_time < 5.0, f"Chunking large text took {processing_time:.2f}s"
        assert len(chunks) > 0

        # Calculate processing rate
        chars_per_second = len(large_text) / processing_time
        print(f"Chunking rate: {chars_per_second:.2f} characters/second")

    @pytest.mark.performance
    def test_memory_usage(self):
        """Test memory usage during processing."""
        process = psutil.Process()
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB

        # Create multiple processors
        processors = []
        for i in range(10):
            processor = MathematicalProcessor(enable_sympy=True)
            processors.append(processor)

        # Process some equations
        for processor in processors:
            for equation in [
                "E = mc^2",
                "\\frac{d}{dx}[f(x)]",
                    "\\int_0^1 x dx"]:
                result = processor.process_equation(equation)
                assert result is not None

        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_increase = final_memory - initial_memory

        # Memory increase should be reasonable
        assert memory_increase < 100, f"Memory increased by {memory_increase:.1f} MB"
        print(
            f"Memory usage: {initial_memory:.1f} MB -> {final_memory:.1f} MB (+{memory_increase:.1f} MB)")

    @pytest.mark.performance
    @pytest.mark.slow
    def test_large_document_processing(self, sample_documents):
        """Test processing large documents."""
        if not sample_documents:
            pytest.skip("No sample documents available")

        # Use the largest available document
        largest_doc = max(sample_documents, key=lambda f: f.stat().st_size)

        with open(largest_doc, 'r', encoding='utf-8') as f:
            content = f.read()

        chunker = EnhancedChunker(chunk_size=1000, overlap_ratio=0.2)

        start_time = time.time()
        chunks = chunker.chunk_text(content, largest_doc.stem)
        end_time = time.time()

        processing_time = end_time - start_time
        doc_size_mb = len(content) / 1024 / 1024

        # Should process large document in reasonable time
        assert processing_time < 30.0, f"Processing large document took {processing_time:.2f}s"
        assert len(chunks) > 0

        # Calculate processing rate
        mb_per_second = doc_size_mb / processing_time
        print(f"Large document processing: {mb_per_second:.2f} MB/second")
        print(f"Document size: {doc_size_mb:.2f} MB, Chunks: {len(chunks)}")


class TestScalabilityBenchmarks:
    """Scalability benchmark tests."""

    @pytest.mark.performance
    @pytest.mark.slow
    def test_concurrent_processing(self):
        """Test concurrent processing performance."""
        import threading
        import queue

        def process_equations(processor, equations, results_queue):
            """Process equations in a separate thread."""
            for equation in equations:
                result = processor.process_equation(equation)
                results_queue.put(result)

        # Create multiple processors
        processors = [
            MathematicalProcessor(
                enable_sympy=True) for _ in range(4)]
        equations = ["E = mc^2", "\\frac{d}{dx}[f(x)]", "\\int_0^1 x dx"] * 10

        # Split equations among processors
        equations_per_processor = len(equations) // len(processors)
        equation_chunks = [equations[i:i + equations_per_processor]
                           for i in range(0, len(equations), equations_per_processor)]

        # Create results queue
        results_queue = queue.Queue()

        # Start threads
        threads = []
        start_time = time.time()

        for processor, equation_chunk in zip(processors, equation_chunks):
            thread = threading.Thread(
                target=process_equations,
                args=(processor, equation_chunk, results_queue)
            )
            thread.start()
            threads.append(thread)

        # Wait for all threads to complete
        for thread in threads:
            thread.join()

        end_time = time.time()
        processing_time = end_time - start_time

        # Collect results
        results = []
        while not results_queue.empty():
            results.append(results_queue.get())

        # Verify all equations were processed
        assert len(results) == len(equations)

        # Concurrent processing should be faster than sequential
        print(f"Concurrent processing time: {processing_time:.2f}s")
        print(
            f"Processed {len(equations)} equations with {len(processors)} threads")

    @pytest.mark.performance
    def test_batch_processing_performance(self, enhanced_chunker):
        """Test batch processing performance."""
        # Create multiple test documents
        test_documents = []
        for i in range(10):
            content = f"Document {i}: This is test content with some mathematical equations like E = mc^2."
            test_documents.append(content)

        start_time = time.time()

        all_chunks = []
        for i, content in enumerate(test_documents):
            chunks = enhanced_chunker.chunk_text(content, f"doc_{i}")
            all_chunks.extend(chunks)

        end_time = time.time()
        processing_time = end_time - start_time

        # Should process multiple documents efficiently
        assert processing_time < 10.0, f"Batch processing took {processing_time:.2f}s"
        assert len(all_chunks) > 0

        print(
            f"Batch processing: {len(test_documents)} documents, {len(all_chunks)} chunks in {processing_time:.2f}s")


class TestResourceUsageBenchmarks:
    """Resource usage benchmark tests."""

    @pytest.mark.performance
    def test_cpu_usage(self, mathematical_processor, sample_equations):
        """Test CPU usage during processing."""
        process = psutil.Process()

        # Get initial CPU usage
        initial_cpu = process.cpu_percent()

        # Process equations
        for equation in sample_equations * 5:
            result = mathematical_processor.process_equation(equation)
            assert result is not None

        # Get final CPU usage
        final_cpu = process.cpu_percent()

        # CPU usage should be reasonable
        assert final_cpu < 100, f"CPU usage: {final_cpu}%"
        print(f"CPU usage: {initial_cpu}% -> {final_cpu}%")

    @pytest.mark.performance
    def test_memory_leak_detection(self):
        """Test for memory leaks during repeated processing."""
        process = psutil.Process()
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB

        # Process many equations repeatedly
        processor = MathematicalProcessor(enable_sympy=True)
        equations = ["E = mc^2", "\\frac{d}{dx}[f(x)]", "\\int_0^1 x dx"]

        for iteration in range(100):
            for equation in equations:
                result = processor.process_equation(equation)
                assert result is not None

            # Check memory every 10 iterations
            if iteration % 10 == 0:
                current_memory = process.memory_info().rss / 1024 / 1024  # MB
                memory_increase = current_memory - initial_memory

                # Memory increase should not be excessive
                assert memory_increase < 50, f"Memory leak detected: {memory_increase:.1f} MB increase"

        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        total_memory_increase = final_memory - initial_memory

        print(
            f"Memory usage after 300 operations: {total_memory_increase:.1f} MB increase")

    @pytest.mark.performance
    def test_processing_time_consistency(self, mathematical_processor):
        """Test that processing times are consistent."""
        equation = "E = mc^2"
        processing_times = []

        # Process the same equation multiple times
        for _ in range(20):
            start_time = time.time()
            result = mathematical_processor.process_equation(equation)
            end_time = time.time()

            processing_times.append(end_time - start_time)
            assert result is not None

        # Calculate statistics
        mean_time = statistics.mean(processing_times)
        std_time = statistics.stdev(processing_times)
        max_time = max(processing_times)
        min_time = min(processing_times)

        # Processing time should be consistent
        assert std_time < mean_time * \
            0.5, f"Processing time too variable: std={std_time:.4f}, mean={mean_time:.4f}"
        assert max_time < mean_time * \
            2, f"Maximum processing time too high: {max_time:.4f}s"

        print(
            f"Processing time consistency: mean={mean_time:.4f}s, std={std_time:.4f}s, range=[{min_time:.4f}, {max_time:.4f}]")


class TestPerformanceThresholds:
    """Test performance against defined thresholds."""

    @pytest.mark.performance
    def test_mathematical_processing_threshold(self, mathematical_processor):
        """Test mathematical processing meets performance threshold."""
        equation = "E = mc^2"

        start_time = time.time()
        result = mathematical_processor.process_equation(equation)
        end_time = time.time()

        processing_time = end_time - start_time

        # Should process simple equation in under 0.1 seconds
        assert processing_time < 0.1, f"Mathematical processing too slow: {processing_time:.4f}s"

    @pytest.mark.performance
    def test_content_classification_threshold(self, content_classifier):
        """Test content classification meets performance threshold."""
        text = "This is regular prose text."

        start_time = time.time()
        content_type = content_classifier.classify_content(text, {})
        end_time = time.time()

        processing_time = end_time - start_time

        # Should classify text in under 0.01 seconds
        assert processing_time < 0.01, f"Content classification too slow: {processing_time:.4f}s"

    @pytest.mark.performance
    def test_chunking_threshold(self, enhanced_chunker):
        """Test chunking meets performance threshold."""
        text = "This is a test document with multiple sentences. " * 100  # ~5000 chars

        start_time = time.time()
        chunks = enhanced_chunker.chunk_text(text, "test_doc")
        end_time = time.time()

        processing_time = end_time - start_time

        # Should chunk 5000 characters in under 1 second
        assert processing_time < 1.0, f"Chunking too slow: {processing_time:.4f}s"
        assert len(chunks) > 0