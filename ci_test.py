#!/usr/bin/env python3
"""
    --- AUTO-GENERATED DOCSTRING ---
    Table of content is automatically generated by Agent Docstrings v1.3.5
    
    Classes/Functions:
        - CITestRunner (line 41):
            - run_ci_tests(quick: bool = False, coverage: bool = False) -> Dict[str, Any] (line 49)
            - _test_imports() -> Dict[str, Any] (line 122)
            - _test_basic_functionality() -> Dict[str, Any] (line 140)
            - _test_configuration() -> Dict[str, Any] (line 158)
            - _run_unit_tests() -> Dict[str, Any] (line 182)
            - _run_integration_tests() -> Dict[str, Any] (line 217)
            - _test_error_handling() -> Dict[str, Any] (line 251)
            - _run_coverage() (line 273)
        - main() (line 300)
    --- END AUTO-GENERATED DOCSTRING ---

CI/CD Test Runner for Enhanced SciRAG

This script is designed for continuous integration environments.
It runs essential tests quickly and provides clear pass/fail results.

Usage:
    python ci_test.py                    # Run all CI tests
    python ci_test.py --quick            # Run only quick tests
    python ci_test.py --coverage         # Run with coverage
"""
import sys
import os
import time
import subprocess
from pathlib import Path
from typing import Dict, Any

# Add the project root to Python path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))


class CITestRunner:
    """CI/CD test runner for Enhanced SciRAG."""

    def __init__(self):
        self.project_root = project_root
        self.start_time = time.time()
        self.results = {}

    def run_ci_tests(self, quick: bool = False,
                     coverage: bool = False) -> Dict[str, Any]:
        """Run CI tests."""
        print("🚀 Enhanced SciRAG CI Tests")
        print("=" * 40)

        if quick:
            print("⚡ Quick CI Tests Mode")
            test_suites = [
                ("Import Tests", self._test_imports),
                ("Basic Functionality", self._test_basic_functionality),
                ("Configuration", self._test_configuration),
            ]
        else:
            print("🔍 Full CI Tests Mode")
            test_suites = [
                ("Import Tests", self._test_imports),
                ("Basic Functionality", self._test_basic_functionality),
                ("Configuration", self._test_configuration),
                ("Unit Tests", self._run_unit_tests),
                ("Integration Tests", self._run_integration_tests),
                ("Error Handling", self._test_error_handling),
            ]

        total_passed = 0
        total_failed = 0

        for suite_name, test_func in test_suites:
            print(f"\n📋 {suite_name}...")
            try:
                result = test_func()
                if result['passed']:
                    print(f"  ✅ {suite_name}: PASSED")
                    total_passed += result['tests_passed']
                else:
                    print(f"  ❌ {suite_name}: FAILED")
                    total_failed += result['tests_failed']
                self.results[suite_name] = result
            except Exception as e:
                print(f"  💥 {suite_name}: ERROR - {e}")
                self.results[suite_name] = {
                    'passed': False,
                    'error': str(e),
                    'tests_passed': 0,
                    'tests_failed': 1
                }
                total_failed += 1

        # Run coverage if requested
        if coverage:
            self._run_coverage()

        # Generate summary
        duration = time.time() - self.start_time
        total_tests = total_passed + total_failed

        print(f"\n📊 CI Test Summary")
        print("=" * 30)
        print(f"Total Tests: {total_tests}")
        print(f"Passed: {total_passed}")
        print(f"Failed: {total_failed}")
        print(f"Success Rate: {(total_passed/total_tests*100):.1f}%")
        print(f"Duration: {duration:.2f}s")

        return {
            'total_tests': total_tests,
            'passed': total_passed,
            'failed': total_failed,
            'success_rate': total_passed / total_tests * 100,
            'duration': duration,
            'results': self.results
        }

    def _test_imports(self) -> Dict[str, Any]:
        """Test that all modules can be imported."""
        try:
            # Test core imports
            from scirag import SciRag, SciRagEnhanced
            from scirag.config import enhanced_config

            # Test enhanced processing imports
            from scirag.enhanced_processing import (
                MathematicalProcessor, ContentClassifier, EnhancedChunker,
                AssetProcessor, GlossaryExtractor, EnhancedChunk, ContentType
            )

            return {'passed': True, 'tests_passed': 1, 'tests_failed': 0}
        except ImportError as e:
            print(f"    Import error: {e}")
            return {'passed': False, 'tests_passed': 0, 'tests_failed': 1}

    def _test_basic_functionality(self) -> Dict[str, Any]:
        """Test basic functionality."""
        try:
            from scirag.enhanced_processing import MathematicalProcessor

            processor = MathematicalProcessor(enable_sympy=True)
            result = processor.process_equation("E = mc^2")

            if (result is not None and
                result['equation_type'] == 'equation' and
                    result['complexity_score'] > 0):
                return {'passed': True, 'tests_passed': 1, 'tests_failed': 0}
            else:
                return {'passed': False, 'tests_passed': 0, 'tests_failed': 1}
        except Exception as e:
            print(f"    Functionality error: {e}")
            return {'passed': False, 'tests_passed': 0, 'tests_failed': 1}

    def _test_configuration(self) -> Dict[str, Any]:
        """Test configuration."""
        try:
            from scirag.config import enhanced_config

            # Test configuration access
            required_attrs = [
                'ENABLE_ENHANCED_PROCESSING',
                'ENABLE_MATHEMATICAL_PROCESSING',
                'ENABLE_ASSET_PROCESSING',
                'ENABLE_GLOSSARY_EXTRACTION'
            ]

            has_required_attrs = all(hasattr(enhanced_config, attr)
                                     for attr in required_attrs)

            if has_required_attrs:
                return {'passed': True, 'tests_passed': 1, 'tests_failed': 0}
            else:
                return {'passed': False, 'tests_passed': 0, 'tests_failed': 1}
        except Exception as e:
            print(f"    Configuration error: {e}")
            return {'passed': False, 'tests_passed': 0, 'tests_failed': 1}

    def _run_unit_tests(self) -> Dict[str, Any]:
        """Run unit tests using pytest."""
        try:
            result = subprocess.run([
                sys.executable, "-m", "pytest",
                "tests/test_unit_components.py",
                "-v", "--tb=short"
            ], capture_output=True, text=True, timeout=300)

            if result.returncode == 0:
                # Count passed tests from output
                passed_count = result.stdout.count('PASSED')
                return {
                    'passed': True,
                    'tests_passed': passed_count,
                    'tests_failed': 0}
            else:
                failed_count = result.stdout.count('FAILED')
                return {
                    'passed': False,
                    'tests_passed': 0,
                    'tests_failed': failed_count}
        except subprocess.TimeoutExpired:
            return {
                'passed': False,
                'tests_passed': 0,
                'tests_failed': 1,
                'error': 'Timeout'}
        except Exception as e:
            return {
                'passed': False,
                'tests_passed': 0,
                'tests_failed': 1,
                'error': str(e)}

    def _run_integration_tests(self) -> Dict[str, Any]:
        """Run integration tests using pytest."""
        try:
            result = subprocess.run([
                sys.executable, "-m", "pytest",
                "tests/test_integration_system.py",
                "-v", "--tb=short"
            ], capture_output=True, text=True, timeout=300)

            if result.returncode == 0:
                passed_count = result.stdout.count('PASSED')
                return {
                    'passed': True,
                    'tests_passed': passed_count,
                    'tests_failed': 0}
            else:
                failed_count = result.stdout.count('FAILED')
                return {
                    'passed': False,
                    'tests_passed': 0,
                    'tests_failed': failed_count}
        except subprocess.TimeoutExpired:
            return {
                'passed': False,
                'tests_passed': 0,
                'tests_failed': 1,
                'error': 'Timeout'}
        except Exception as e:
            return {
                'passed': False,
                'tests_passed': 0,
                'tests_failed': 1,
                'error': str(e)}

    def _test_error_handling(self) -> Dict[str, Any]:
        """Test error handling."""
        try:
            from scirag.enhanced_processing import MathematicalProcessor

            processor = MathematicalProcessor(enable_sympy=True)

            # Test with invalid input
            result1 = processor.process_equation("")
            if result1 is None:
                return {'passed': False, 'tests_passed': 0, 'tests_failed': 1}

            # Test with malformed input
            result2 = processor.process_equation("invalid latex \\invalid{")
            if result2 is None:
                return {'passed': False, 'tests_passed': 0, 'tests_failed': 1}

            return {'passed': True, 'tests_passed': 2, 'tests_failed': 0}
        except Exception as e:
            print(f"    Error handling error: {e}")
            return {'passed': False, 'tests_passed': 0, 'tests_failed': 1}

    def _run_coverage(self):
        """Run coverage analysis."""
        print("\n📊 Running Coverage Analysis...")
        try:
            result = subprocess.run([
                sys.executable, "-m", "pytest",
                "--cov=scirag",
                "--cov-report=term",
                "--cov-report=html"
            ], capture_output=True, text=True, timeout=600)

            if result.returncode == 0:
                print("✅ Coverage analysis completed")
                # Extract coverage percentage from output
                lines = result.stdout.split('\n')
                for line in lines:
                    if 'TOTAL' in line and '%' in line:
                        print(f"📈 {line.strip()}")
            else:
                print("❌ Coverage analysis failed")
                print(result.stderr)
        except subprocess.TimeoutExpired:
            print("⏰ Coverage analysis timed out")
        except Exception as e:
            print(f"💥 Coverage analysis error: {e}")


def main():
    """Main entry point."""
    import argparse

    parser = argparse.ArgumentParser(
        description="Enhanced SciRAG CI Test Runner")
    parser.add_argument(
        "--quick",
        action="store_true",
        help="Run only quick tests")
    parser.add_argument(
        "--coverage",
        action="store_true",
        help="Run with coverage")

    args = parser.parse_args()

    runner = CITestRunner()
    result = runner.run_ci_tests(quick=args.quick, coverage=args.coverage)

    # Exit with appropriate code
    if result['failed'] > 0:
        print(f"\n❌ CI Tests Failed: {result['failed']} tests failed")
        sys.exit(1)
    else:
        print(f"\n✅ CI Tests Passed: {result['passed']} tests passed")
        sys.exit(0)


if __name__ == "__main__":
    main()