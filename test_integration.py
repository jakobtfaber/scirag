#!/usr/bin/env python3
"""
    --- AUTO-GENERATED DOCSTRING ---
    Table of content is automatically generated by Agent Docstrings v1.3.5
    
    Classes/Functions:
        - test_enhanced_scirag_integration() (line 26)
        - test_standalone_components() (line 189)
    --- END AUTO-GENERATED DOCSTRING ---

Comprehensive Integration Test for Enhanced SciRAG

This script tests the full integration of Enhanced SciRAG with the main SciRAG system,
including document processing, chunking, and response generation.
"""
import os
import sys
import time
from pathlib import Path

# Add the project root to the Python path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))


def test_enhanced_scirag_integration():
    """Test full Enhanced SciRAG integration."""
    print("🔗 Testing Enhanced SciRAG Integration")
    print("=" * 50)

    try:
        # Test imports
        print("\n1. Testing Imports...")
        from scirag import SciRag, SciRagEnhanced
        from scirag.enhanced_processing import (
            MathematicalProcessor, ContentClassifier, EnhancedChunker,
            AssetProcessor, GlossaryExtractor
        )
        print("   ✅ All imports successful")

        # Test Enhanced SciRAG initialization
        print("\n2. Testing Enhanced SciRAG Initialization...")
        try:
            # Initialize without credentials (standalone mode)
            enhanced_scirag = SciRagEnhanced(
                client=None,
                credentials=None,
                markdown_files_path=None,
                corpus_name="test_corpus",
                gen_model="gpt-4",
                enable_enhanced_processing=True,
                enable_mathematical_processing=True,
                enable_asset_processing=True,
                enable_glossary_extraction=True,
                enable_enhanced_chunking=True,
                chunk_size=1000,
                chunk_overlap=200,
                fallback_on_error=True
            )
            print("   ✅ Enhanced SciRAG initialized successfully")
        except Exception as e:
            print(f"   ❌ Error initializing Enhanced SciRAG: {e}")
            return False

        # Test document processing
        print("\n3. Testing Document Processing...")
        txt_files_dir = project_root / "txt_files"
        if txt_files_dir.exists():
            txt_files = list(txt_files_dir.glob("*.txt")
                             )[:2]  # Test first 2 files

            if txt_files:
                print(f"   📁 Found {len(txt_files)} test documents")

                try:
                    # Test enhanced document loading
                    file_paths = [str(f) for f in txt_files]
                    source_ids = [f.stem for f in txt_files]

                    print("   🔄 Processing documents with enhanced processing...")
                    start_time = time.time()

                    enhanced_chunks = enhanced_scirag.load_documents_enhanced(
                        file_paths=file_paths,
                        source_ids=source_ids
                    )

                    processing_time = time.time() - start_time

                    print(f"   ⏱️  Processing time: {processing_time:.2f}s")
                    print(
                        f"   📦 Generated {len(enhanced_chunks)} enhanced chunks")

                    if enhanced_chunks:
                        # Analyze chunk content
                        math_chunks = [
                            c for c in enhanced_chunks if c.is_mathematical()]
                        asset_chunks = [
                            c for c in enhanced_chunks if c.is_asset()]
                        glossary_chunks = [
                            c for c in enhanced_chunks if c.is_glossary()]

                        print(f"   🧮 Mathematical chunks: {len(math_chunks)}")
                        print(f"   🖼️  Asset chunks: {len(asset_chunks)}")
                        print(f"   📚 Glossary chunks: {len(glossary_chunks)}")

                        # Test chunk filtering
                        print("\n4. Testing Chunk Filtering...")
                        math_only = enhanced_scirag.get_mathematical_chunks()
                        asset_only = enhanced_scirag.get_asset_chunks()
                        glossary_only = enhanced_scirag.get_glossary_chunks()

                        print(
                            f"   🧮 Mathematical chunks (filtered): {len(math_only)}")
                        print(
                            f"   🖼️  Asset chunks (filtered): {len(asset_only)}")
                        print(
                            f"   📚 Glossary chunks (filtered): {len(glossary_only)}")

                        # Test processing statistics
                        print("\n5. Testing Processing Statistics...")
                        stats = enhanced_scirag.get_processing_stats()
                        print(
                            f"   📊 Enhanced processing enabled: {stats['enhanced_processing_enabled']}")
                        print(
                            f"   📊 Mathematical processing enabled: {stats['mathematical_processing_enabled']}")
                        print(
                            f"   📊 Documents processed: {stats['documents_processed']}")
                        print(
                            f"   📊 Chunks created: {stats['chunks_created']}")
                        print(
                            f"   📊 Mathematical content: {stats['mathematical_content_processed']}")
                        print(
                            f"   📊 Assets processed: {stats['assets_processed']}")
                        print(
                            f"   📊 Glossary terms: {stats['glossary_terms_extracted']}")
                        print(
                            f"   📊 Processing time: {stats['processing_time']:.2f}s")
                        print(f"   📊 Errors: {stats['errors']}")

                        # Test chunk validation
                        print("\n6. Testing Chunk Validation...")
                        validation = enhanced_scirag.validate_enhanced_chunks()
                        print(
                            f"   📊 Total chunks: {validation['total_chunks']}")
                        print(
                            f"   📊 Valid chunks: {validation['valid_chunks']}")
                        print(
                            f"   📊 Invalid chunks: {validation['invalid_chunks']}")
                        print(
                            f"   📊 Content type distribution: {validation['content_type_distribution']}")

                        # Test export functionality
                        print("\n7. Testing Export Functionality...")
                        try:
                            json_export = enhanced_scirag.export_enhanced_chunks(
                                'json')
                            print(
                                f"   ✅ JSON export successful ({len(json_export)} characters)")

                            csv_export = enhanced_scirag.export_enhanced_chunks(
                                'csv')
                            print(
                                f"   ✅ CSV export successful ({len(csv_export)} characters)")
                        except Exception as e:
                            print(f"   ⚠️  Export test failed: {e}")

                        print(
                            "\n   ✅ Document processing test completed successfully")
                    else:
                        print("   ⚠️  No chunks generated")

                except Exception as e:
                    print(f"   ❌ Error processing documents: {e}")
                    return False
            else:
                print("   ⚠️  No test documents found")
        else:
            print("   ⚠️  txt_files directory not found")

        print("\n🎉 Enhanced SciRAG Integration Test Completed Successfully!")
        return True

    except Exception as e:
        print(f"\n❌ Integration test failed: {e}")
        return False


def test_standalone_components():
    """Test standalone enhanced processing components."""
    print("\n🔧 Testing Standalone Components")
    print("=" * 40)

    try:
        from scirag.enhanced_processing import (
            MathematicalProcessor, ContentClassifier, EnhancedChunker,
            AssetProcessor, GlossaryExtractor
        )

        # Test mathematical processor
        print("\n1. Testing Mathematical Processor...")
        math_processor = MathematicalProcessor(enable_sympy=True)
        result = math_processor.process_equation("E = mc^2")
        print(f"   ✅ Equation type: {result['equation_type']}")
        print(f"   ✅ Complexity: {result['complexity_score']}")

        # Test content classifier
        print("\n2. Testing Content Classifier...")
        classifier = ContentClassifier()
        content_types = [
            "This is regular prose content.",
            "Figure 1: A diagram showing the process.",
            "Table 2: Experimental results are shown below.",
            "The equation E = mc^2 represents energy equivalence."
        ]

        for content in content_types:
            content_type = classifier.classify_content(content, {})
            print(f"   ✅ '{content[:30]}...' → {content_type}")

        # Test enhanced chunker
        print("\n3. Testing Enhanced Chunker...")
        chunker = EnhancedChunker(chunk_size=500, overlap_ratio=0.1)
        test_text = "This is a test document with some content. It contains multiple sentences and should be chunked properly."
        chunks = chunker.chunk_text(test_text, "test_doc")
        print(f"   ✅ Generated {len(chunks)} chunks")

        # Test asset processor
        print("\n4. Testing Asset Processor...")
        asset_processor = AssetProcessor()
        asset_result = asset_processor.process_asset(
            "Figure 1: A diagram showing the process", "test_doc")
        if asset_result:
            print(f"   ✅ Asset type: {asset_result.asset_type}")
            print(f"   ✅ Confidence: {asset_result.confidence}")
        else:
            print(f"   ✅ No asset detected (expected for this text)")

        # Test glossary extractor
        print("\n5. Testing Glossary Extractor...")
        glossary_extractor = GlossaryExtractor()
        glossary_result = glossary_extractor.extract_glossary_terms(
            "The term 'energy equivalence' refers to the principle that E = mc^2.",
            "test_doc"
        )
        print(f"   ✅ Extracted {len(glossary_result)} glossary terms")

        print("\n   ✅ All standalone components working correctly")
        return True

    except Exception as e:
        print(f"\n   ❌ Standalone component test failed: {e}")
        return False


if __name__ == "__main__":
    print("🚀 Enhanced SciRAG Comprehensive Integration Test")
    print("=" * 60)

    try:
        # Test standalone components first
        standalone_success = test_standalone_components()

        # Test full integration
        integration_success = test_enhanced_scirag_integration()

        if standalone_success and integration_success:
            print(f"\n✅ ALL TESTS PASSED!")
            print(f"   Enhanced SciRAG is fully integrated and ready for production use.")
            print(f"   - Standalone components: ✅ Working")
            print(f"   - Full integration: ✅ Working")
            print(f"   - Document processing: ✅ Working")
            print(f"   - Mathematical processing: ✅ Working")
            print(f"   - Content classification: ✅ Working")
            print(f"   - Enhanced chunking: ✅ Working")
        else:
            print(f"\n❌ Some tests failed.")
            if not standalone_success:
                print(f"   - Standalone components: ❌ Failed")
            if not integration_success:
                print(f"   - Full integration: ❌ Failed")
            sys.exit(1)

    except Exception as e:
        print(f"\n❌ Test suite failed with error: {e}")
        sys.exit(1)